{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YK1XGvB8yAMo"
   },
   "source": [
    "<center><b>DIGHUM101</b></center>\n",
    "<center>3-4: Network analysis</center>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Analysis\n",
    "\n",
    "Let's access the Reddit API to do a small network analysis of \"influencers\" in our data. First, you will need to sign up with Reddit to run some of the code. See **notebook 3-2** for details on how to create an app using the API. \n",
    "\n",
    "Go to https://ssl.reddit.com/prefs/apps/ if you need to check your client id and password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='XXX',\n",
    "                     client_secret='XXX',\n",
    "                     password='XXX',\n",
    "                     user_agent='Get Reddit network data, v1.0, by /u/YOUR_USERNAME',\n",
    "                     username='XXX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network analysis: finding influencers in Reddit data\n",
    "\n",
    "When getting Reddit data, one cannot at a glance see which users are influential. Other social media platforms have follower counts which directly quantify the amount of reach a user is likely to have, while redditors only have karma, i.e., the net total up and down votes since account creation, and a log of their posts and comments in different subreddits. These twose statistics can give a rough idea of a user’s activity.\n",
    "\n",
    "It has already been found that a very small percentage of Reddit’s users create the vast majority of the site’s content, so we would not be surprised if only a few users could influence the discourse of entire subreddits. Identifying these users would help us understand how a subreddit's discourse is shaped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Data/r_conspiracy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get rid of some empty values in our \"selftext\" column, using the `dropna()` method. On Reddit, removed posts get flagged as \"[removed]\" or \"[deleted]\", so we have to get rid of this too. We can do that with the `isin()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['author'].isin(['None', '[removed]', '[deleted]' ])].dropna(subset=['author'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.author.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sort by score and just get the top 1000 posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='score',ascending=False)[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many unique authors do we have in our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.author.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df.score, y=df.num_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this scatter plot shows that the number of comments don’t necessarily increase with posts that have a higher net score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to decide which of these users we consider to be \"influencers\". Let's first have a look at how often these popular authors are posting. We'll select users who have posted to this subreddit (which, remember, is sorted based on popularity) more than twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = df.groupby('author')\n",
    "rep = g.filter(lambda x: len(x) > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of all posts, this is the amount of people who posted more than twice \n",
    "rep.author.nunique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot it\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "p = sns.countplot(x=rep.author, data=rep, order = rep.author.value_counts().index)\n",
    "p.set(title='Distribution of authors and their posts',xlabel=\"Authors\", ylabel=\"Number of posts\");\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">NOTE: Deciding who is an \"influencer\" of course has to do with the size of the subreddit and how often submissions are made. Feel free to play around with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The top three most frequently posting authors\n",
    "rep.author.value_counts().index[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to the API\n",
    "\n",
    "Next, let's find out where else these influencers posted. We'll compile a list of authors that appeared more than once on other subreddits using the Reddit API. In order to form a network graph, we need data about the particular subreddits where our influencers appeared. \n",
    "\n",
    "Let's first define a function that can get us the other posts by the influencers we have found in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_posts(author, n):\n",
    "    try:\n",
    "        redditor = reddit.redditor(author)\n",
    "        user_posts_list = []\n",
    "        for submission in redditor.submissions.top(limit = n):\n",
    "            info_list = []\n",
    "            info_list.append(submission.id)\n",
    "            info_list.append(submission.score)\n",
    "            info_list.append(str(submission.author))\n",
    "            info_list.append(submission.num_comments)\n",
    "            info_list.append(str(submission.subreddit))\n",
    "            user_posts_list.append(info_list)\n",
    "    # Dealing with errors in case redditors have been banned, deleted their accounts, etc.\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    a = sorted(user_posts_list, key=lambda x: x[1], reverse = True)\n",
    "    user_posts_df = pd.DataFrame(a)\n",
    "    return user_posts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_authors = list(rep.author.unique()) # Get a list of all the unique authors\n",
    "authors_df =  pd.DataFrame() # Make an empty dataframe\n",
    "authors_df = authors_df.fillna(0) # Fill it up for now\n",
    "for u in u_authors: # Loops through every \"influencer\" user and gets 10 top posts per user\n",
    "    c = get_user_posts(u, 10)\n",
    "    authors_df = pd.concat([authors_df, c]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_df = authors_df.rename(index=str, #renaming column names \n",
    "                               columns={0: \"id\", 1: \"score\", 2: \"author\", 3: \"num_comments\", 4: \"subreddit\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_df.head(20) # Dataframe of other subreddits where authors posted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize those subreddits with at least 2 or more posts made by the influencers. The Y-axis is the number of submissions and the X-axis are the respective subreddits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = authors_df['subreddit'].value_counts() \n",
    "\n",
    "# Only plot the subreddits that appear more than twice\n",
    "ax = authors_df[authors_df['subreddit'].isin(counts[counts > 2].index)].subreddit.value_counts().plot(kind='bar',title='Distribution of other subreddits where influencers post') \n",
    "ax.set(xlabel=\"Subreddits\", ylabel=\"Number of posts\")\n",
    "plt.savefig(\"BargraphSubreddits\",dpi=150, bbox_inches='tight',pad_inches=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll create a dataframe where each row represents an influencer and a subreddit they have posted in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df = authors_df[['author', 'subreddit']] # Create a dataframe for network graph purposes \n",
    "n_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can save this to a CSV if we want\n",
    "n_df.to_csv('r_conspiracy_edges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize using NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = list(n_df.subreddit.unique()) # Make list of unique subreddits to use in network graph \n",
    "auths = list(n_df.author.unique()) # Make list of unique authors to use in network graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "plt.figure(figsize=(18, 18))\n",
    "\n",
    "# Create the graph from the dataframe\n",
    "g = nx.from_pandas_edgelist(n_df, source='author', target='subreddit') \n",
    "\n",
    "# Create a layout for nodes \n",
    "layout = nx.spring_layout(g,iterations=50,scale=2)\n",
    "\n",
    "# Draw the parts we want, edges thin and grey\n",
    "# Influencers appear small and grey\n",
    "# Subreddits appear in blue and sized according to their respective number of connections.\n",
    "# Labels for subreddits ONLY\n",
    "# People who have more connections are highlighted in color \n",
    "\n",
    "# Go through every subbreddit, ask the graph how many connections it has. \n",
    "# Multiply that by 80 to get the circle size\n",
    "sub_size = [g.degree(sub) * 80 for sub in subs]\n",
    "nx.draw_networkx_nodes(g, \n",
    "                       layout, \n",
    "                       nodelist=subs, \n",
    "                       node_size=sub_size, # a LIST of sizes, based on g.degree\n",
    "                       node_color='lightblue')\n",
    "\n",
    "# Draw all the entities \n",
    "nx.draw_networkx_nodes(g, layout, nodelist=authors_df['author'], node_color='#cccccc', node_size=100)\n",
    "\n",
    "# Draw highly connected influencers \n",
    "influencers = [person for person in authors_df['author'] if g.degree(person) > 1]\n",
    "nx.draw_networkx_nodes(g, layout, nodelist=influencers, node_color='orange', node_size=100)\n",
    "\n",
    "nx.draw_networkx_edges(g, layout, width=1, edge_color=\"#cccccc\")\n",
    "\n",
    "node_labels = dict(zip(subs, subs)) #labels for subs\n",
    "auth_labels = dict(zip(auths, auths)) #labels for authors\n",
    "\n",
    "nx.draw_networkx_labels(g, layout, labels=node_labels)\n",
    "nx.draw_networkx_labels(g, layout, labels=auth_labels)\n",
    "\n",
    "\n",
    "# No axis needed\n",
    "plt.axis('off')\n",
    "plt.title(\"Network Graph of Related Subreddits\")\n",
    "plt.savefig(\"NetworkGraph\", bbox_inches='tight',pad_inches=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting the graph\n",
    "In this graph, influencer nodes appear small and grey. The influencers who have more connections than just r/amitheasshole are highlighted in yellow. The subreddits appear in blue and sized according to their respective number of connections."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Week 2 OPTIONAL - Reddit API.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
