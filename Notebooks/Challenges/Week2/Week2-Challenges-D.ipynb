{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1: spaCy Linguistic Features\n",
    "\n",
    "Use spaCy to create a [linguistic features table](https://spacy.io/usage/linguistic-features). [Part of speech tagging](https://stackabuse.com/python-for-nlp-parts-of-speech-tagging-and-named-entity-recognition/) is a means to \"[assign] parts of speech to individual words in a sentence\". \n",
    "\n",
    "What are the [ten parts of speech](https://www.theclassroom.com/10-parts-speech-8344653.html)?\n",
    "\n",
    "[Click here to view part of speech tagging abbreviations](https://medium.com/@gianpaul.r/tokenization-and-parts-of-speech-pos-tagging-in-pythons-nltk-library-2d30f70af13b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the small pretrained model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: if you want to check the difference in performance between Spacy's small, medium and large\n",
    "models, see [here](https://stackoverflow.com/questions/50487495/what-is-difference-between-en-core-web-sm-en-core-web-mdand-en-core-web-lg-mod)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define our function \n",
    "def lemmatize(tokens):\n",
    "    \"\"\"Return the lemmas for each word in `tokens`.\"\"\"\n",
    "    \n",
    "    # spacy models operate on strings not lists, so we turn the tokens back into\n",
    "    # a string of words\n",
    "    words = ' '.join(tokens)\n",
    "    \n",
    "    # this line does all sorts of processing, including the lemmatization.\n",
    "    # `doc` will be like a list of tokens that we can iterate over\n",
    "    doc = nlp(words)\n",
    "    \n",
    "    # each token in `doc` holds information about that token. The `lemma_`\n",
    "    # attribute holds the lemma of that token represented as a string. For\n",
    "    # performance reasons, the `lemma` (without the trailing underscore) holds\n",
    "    # an integer representation of the token, that we'll rarely ever need.\n",
    "    return [token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ('''I was thinking if off the top of your head you are aware of a \n",
    "generalizable comprehension to quickly stem all words in a list of tokens and \n",
    "how to quickly write up a one-minute example? This will be really useful for \n",
    "students interested in text preprocessing.''').split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-PRON-', 'be', 'think', 'if', 'off', 'the', 'top', 'of', '-PRON-', 'head', '-PRON-', 'be', 'aware', 'of', 'a', 'generalizable', 'comprehension', 'to', 'quickly', 'stem', 'all', 'word', 'in', 'a', 'list', 'of', 'token', 'and', 'how', 'to', 'quickly', 'write', 'up', 'a', 'one', '-', 'minute', 'example', '?', 'this', 'will', 'be', 'really', 'useful', 'for', 'student', 'interested', 'in', 'text', 'preprocessing', '.']\n"
     ]
    }
   ],
   "source": [
    "lemmas = lemmatize(tokens)\n",
    "# Notice that spacy lemmatizes pronouns (e.g. \"you\", \"I\", \"your\") in a funny way '-PRON-'.\n",
    "# It just tells us that they are pronouns, rather than giving us something like\n",
    "# \"your\" -> \"you\".\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another example: \n",
    "    \n",
    "Now that our function is defined, let's try it on another sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['think', ',', 'jumping', ',', 'running', ',', 'quicke', ',', 'eat', ',', 'quickly', '-', 'all', 'in', 'a', 'day', 'work', 'for', '-PRON-', ',', '-PRON-', ',', '-PRON-', ',', 'and', '-PRON-', '!']\n"
     ]
    }
   ],
   "source": [
    "# Does this cell work correctly? Does it give us any extraneous information?\n",
    "tokens2 = (\"Thinking, jumping, running, quicking, eating, quickly - all in a days work for me, you, she, and he!\").split()\n",
    "\n",
    "lemmas2 = lemmatize(tokens2)\n",
    "print(lemmas2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thinking jumping running quicking eating quickly  all in a days work for me you she and he\n"
     ]
    }
   ],
   "source": [
    "# Remove punctuation ...\n",
    "sentence = \"Thinking, jumping, running, quicking, eating, quickly - all in a days work for me, you, she, and he!\"\n",
    "\n",
    "for char in punctuation:\n",
    "    sentence = sentence.replace(char, \"\")\n",
    "    \n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['think', 'jump', 'run', 'quicking', 'eat', 'quickly', 'all', 'in', 'a', 'day', 'work', 'for', '-PRON-', '-PRON-', '-PRON-', 'and', '-PRON-']\n"
     ]
    }
   ],
   "source": [
    "# Re-run the lemmatizer!\n",
    "# Why is \"quickly\" not lemmatized? (Because it is an adverb perhaps? Is 'quicking' a word?)\n",
    "tokens3 = sentence.split()\n",
    "\n",
    "lemmas3 = lemmatize(tokens3)\n",
    "print(lemmas3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to data frame\n",
    "\n",
    "Convert the linguistic features table to a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thinking jumping running quicking eating quickly all in a days work for me you she and he"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\" \".join(tokens3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thinking', 'think', 'VERB', 'VBG', 'ROOT', 'Xxxxx', True, False),\n",
       " ('jumping', 'jump', 'VERB', 'VBG', 'xcomp', 'xxxx', True, False),\n",
       " ('running', 'run', 'VERB', 'VBG', 'amod', 'xxxx', True, False),\n",
       " ('quicking', 'quicking', 'NOUN', 'NN', 'dobj', 'xxxx', True, False),\n",
       " ('eating', 'eat', 'VERB', 'VBG', 'advcl', 'xxxx', True, False),\n",
       " ('quickly', 'quickly', 'ADV', 'RB', 'advmod', 'xxxx', True, False),\n",
       " ('all', 'all', 'ADV', 'RB', 'advmod', 'xxx', True, True),\n",
       " ('in', 'in', 'ADP', 'IN', 'prep', 'xx', True, True),\n",
       " ('a', 'a', 'DET', 'DT', 'det', 'x', True, True),\n",
       " ('days', 'day', 'NOUN', 'NNS', 'pobj', 'xxxx', True, False),\n",
       " ('work', 'work', 'NOUN', 'NN', 'advcl', 'xxxx', True, False),\n",
       " ('for', 'for', 'ADP', 'IN', 'prep', 'xxx', True, True),\n",
       " ('me', 'me', 'PRON', 'PRP', 'pobj', 'xx', True, True),\n",
       " ('you', 'you', 'PRON', 'PRP', 'npadvmod', 'xxx', True, True),\n",
       " ('she', 'she', 'PRON', 'PRP', 'appos', 'xxx', True, True),\n",
       " ('and', 'and', 'CCONJ', 'CC', 'cc', 'xxx', True, True),\n",
       " ('he', 'he', 'PRON', 'PRP', 'conj', 'xx', True, True)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define doc\n",
    "doc = nlp(\" \".join(tokens3))\n",
    "\n",
    "d = []\n",
    "for token in doc:\n",
    "    d.append((token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          token.shape_, token.is_alpha, token.is_stop))\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>dep</th>\n",
       "      <th>shape</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thinking</td>\n",
       "      <td>think</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBG</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jumping</td>\n",
       "      <td>jump</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBG</td>\n",
       "      <td>xcomp</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>running</td>\n",
       "      <td>run</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBG</td>\n",
       "      <td>amod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quicking</td>\n",
       "      <td>quicking</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>dobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eating</td>\n",
       "      <td>eat</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBG</td>\n",
       "      <td>advcl</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>quickly</td>\n",
       "      <td>quickly</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>advmod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>advmod</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>days</td>\n",
       "      <td>day</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>pobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>work</td>\n",
       "      <td>work</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>advcl</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>me</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>pobj</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>you</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>npadvmod</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>she</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>appos</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CC</td>\n",
       "      <td>cc</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>he</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>conj</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text     lemma    pos  tag       dep  shape  is_alpha  is_stop\n",
       "0   Thinking     think   VERB  VBG      ROOT  Xxxxx      True    False\n",
       "1    jumping      jump   VERB  VBG     xcomp   xxxx      True    False\n",
       "2    running       run   VERB  VBG      amod   xxxx      True    False\n",
       "3   quicking  quicking   NOUN   NN      dobj   xxxx      True    False\n",
       "4     eating       eat   VERB  VBG     advcl   xxxx      True    False\n",
       "5    quickly   quickly    ADV   RB    advmod   xxxx      True    False\n",
       "6        all       all    ADV   RB    advmod    xxx      True     True\n",
       "7         in        in    ADP   IN      prep     xx      True     True\n",
       "8          a         a    DET   DT       det      x      True     True\n",
       "9       days       day   NOUN  NNS      pobj   xxxx      True    False\n",
       "10      work      work   NOUN   NN     advcl   xxxx      True    False\n",
       "11       for       for    ADP   IN      prep    xxx      True     True\n",
       "12        me    -PRON-   PRON  PRP      pobj     xx      True     True\n",
       "13       you    -PRON-   PRON  PRP  npadvmod    xxx      True     True\n",
       "14       she    -PRON-   PRON  PRP     appos    xxx      True     True\n",
       "15       and       and  CCONJ   CC        cc    xxx      True     True\n",
       "16        he    -PRON-   PRON  PRP      conj     xx      True     True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pd.DataFrame(d, columns=(\"text\", \"lemma\", \"pos\", \"tag\", \"dep\", \"shape\", \n",
    "                               \"is_alpha\", \"is_stop\"))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we want to maintain pronouns instead of using spaCy's '-PRON-' tag? \n",
    "# We could do something like this:\n",
    "\n",
    "doc = nlp(\" \".join(tokens3))\n",
    "\n",
    "d = []\n",
    "for token in doc:\n",
    "    if token.lemma_ != '-PRON-':\n",
    "        d.append((token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop))\n",
    "    else:\n",
    "        d.append((token.text, token.lower_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2: Repeat\n",
    "\n",
    "Repeat Challenge 1 with a text of your choosing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3: Context\n",
    "\n",
    "If you are doing anything that involves text for your individual final project, be sure to start thinking about **_why_** you might want to use n-grams, word2vec, or BERT instead of single-word tokenization. Start brainstorming now even if it all doesn't make total yet!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
